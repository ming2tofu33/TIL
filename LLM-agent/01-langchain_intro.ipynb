{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e1859a",
   "metadata": {},
   "source": [
    "# `01-langchain.ipynb`\n",
    "\n",
    "# Langchain Intro\n",
    "\n",
    "- LLM powered 어플리케이션 제작을 위한 프레임 워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184da0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# %pip install -q langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38375310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77699ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAoO5pSsRENAjk7ZwUWPtAX7tv0ES', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8a5ab943-40a1-4e8a-96a2-fc5967d4129a-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ffe2299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 우리가, 외국어로 메세지가 들어오면 한국어로 번역을 해주는 AI 를 만들고 싶다면?\n",
    "msg = input('외국어를 넣으세요')\n",
    "\n",
    "res = llm.invoke(f'한국어로 번역해줘: {msg}')\n",
    "\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a182d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Mangiamo il pranzo. Cosa ti piacerebbe mangiare?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 52, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAohgHuSQoZAQbJXGwbZ0e2DkPArA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--efc5ef71-a28f-408e-b017-a51a2ba8f4ff-0', usage_metadata={'input_tokens': 52, 'output_tokens': 18, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    # 채팅 세션의 전체적인 안내 사항\n",
    "    SystemMessage(content='한국어를 이탈리어로 번역해줘'),\n",
    "    HumanMessage(content='점심을 먹자. 뭘 먹는게 좋을까?')\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a2ed398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='吃饱了', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 33, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqGehKy5v0D11srxeiaBolVHLMEL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9ea79942-3956-4477-a928-f3ec7257951f-0', usage_metadata={'input_tokens': 33, 'output_tokens': 6, 'total_tokens': 39, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    # 채팅 세션의 전체적인 안내 사항\n",
    "    {'role': 'system', 'content': '한국어를 중국어로 번역해줘'},\n",
    "    {'role': 'human', 'content': '배부르다'}\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58f91466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|吃|饱|了|。||"
     ]
    }
   ],
   "source": [
    "for token in llm.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e4dc45",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "- 고정된 문자열과 변수를 조합하여 프롬프트를 만드는 방법\n",
    "## Chain\n",
    "- Langchain의 각 구성요소를 묶어서(chaining) 한번에 실행(invoke)할 수 있도록 하는 기능\n",
    "- a | b | c 형태로 나옴. 이건 Python 문법이 아니라 Langchain 문법(LCEL-LanChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6320669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='寿司が食べたいです。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 30, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CArjnrJoRngBgwRsDEhHnOdXR4ThY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--69522b33-042e-4f11-911f-495665fd089a-0', usage_metadata={'input_tokens': 30, 'output_tokens': 12, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채팅을 할 경우에는 ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'Translate Korean to {lang}'},\n",
    "    {'role': 'human', 'content': '{text}'}\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "prompt = prompt_template.invoke({'lang': '일본어', 'text': '초밥이 먹고싶다'})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dbc4503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I want to eat a burger.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 27, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CArjvHPOhzYnGo0jSbbaEz74mU3kX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--18811b13-618d-41f7-b339-52d9992e9ac2-0', usage_metadata={'input_tokens': 27, 'output_tokens': 7, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({'lang': '영어', 'text': '버거가 먹고싶다'})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9bffb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to eat kimchi stew.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# a | b | c => \n",
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "chain.invoke({'lang': '영어', 'text': '김치찌개가 먹고싶다'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f3c0ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 데이터 수집: 2025년 1월부터 6월까지의 매출 데이터를 수집합니다. 이 데이터는 일일 또는 월별 매출액, 제품 별 판매량, 지역 별 매출 등을 포함해야 합니다.\n",
      "\n",
      "2. 데이터 정제: 수집된 데이터 중에 결측치나 이상치를 확인하고 처리합니다. 또한 필요한 변수들을 선택하고 인코딩 또는 스케일링 등의 전처리를 해줍니다.\n",
      "\n",
      "3. 탐색적 데이터 분석 (EDA): 데이터 시각화를 통해 매출의 추이, 판매량의 변화, 지역 별 매출 비교 등을 분석합니다. 주요 지표들을 히스토그램, 상자 그림, 산점도, 라인 플롯 등으로 시각화하여 비교 및 결론을 도출합니다.\n",
      "\n",
      "4. 시계열 분석: 시계열 데이터를 분석하여 매출의 계절성, 트렌드, 주기성 등을 확인하고 예측 모형을 만들어 전반기 매출을 예측합니다.\n",
      "\n",
      "5. 클라이언트에게 결과 전달: 분석 결과를 클라이언트에게 보고서 형태로 전달하여 매출의 특징, 주요 요인 및 추이 등을 설명하고 향후 전략 수립에 도움이 될 수 있는 인사이트를 제공합니다.\n"
     ]
    }
   ],
   "source": [
    "# 단발성 명령 수행 PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "당신은 클라이언트 요구사항을 분석해서 단계를 나눠주는 데이터분석 전문가 입니다.\n",
    "사용자의 질문을 EDA에 활용할 수 있도록 단계를 나눠주세요\n",
    "\n",
    "질문: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "res = chain.invoke({'question': '이번 2025년 전반기 매출 분석'})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba1598f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분석 단계:\n",
      "1. 데이터 수집: 2025년 전반기 매출 데이터 수집\n",
      "2. 데이터 전처리: 수집된 데이터를 정리하고 필요한 형식으로 변환\n",
      "3. 탐색적 데이터 분석 (EDA): 매출 데이터를 시각화하고 통계적 분석을 통해 트렌드 및 패턴 파악\n",
      "4. 매출 추이 분석: 전반기 동안의 매출 추이를 분석하여 변동 요인 및 성과를 파악\n",
      "5. 제품/서비스별 매출 비교: 제품 또는 서비스별로 매출을 비교하여 성과 및 인기 상품/서비스를 파악\n",
      "6. 매출 예측: EDA 결과를 기반으로 매출의 향후 예측 및 추이를 분석\n",
      "7. 결과 도출: 데이터 분석을 토대로 2025년 전반기 매출에 대한 결론 및 제언 도출\n",
      "\n",
      "이러한 단계들을 따라 분석을 진행하면 요구사항에 대한 상세하고 신뢰할 수 있는 결과물을 도출할 수 있을 것입니다."
     ]
    }
   ],
   "source": [
    "# chain 은 Runnable 객체이기 때문에 invoke, stream, batch 메서드 사용가능\n",
    "for token in chain.stream({'question': '이번 2025년 전반기 매출 분석'}):\n",
    "    print(token, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f336f8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Langchain은 자연어 처리(NLP) 애플리케이션을 쉽게 개발할 수 있도록 도와주는 Python 라이브러리입니다. 이 라이브러리는 언어 모델과 다양한 데이터 소스, 도구들을 효과적으로 연결하여 복잡한 대화형 시스템이나 자동화된 작업을 구현하는 데 사용됩니다. 또한, 사용자 맞춤형 챗봇이나 지식 베이스 구축에 유용하며, 개발자가 빠르게 프로토타입을 만들고 배포할 수 있게 지원합니다.',\n",
       " 'Langsmith는 AI 기반의 자연어 처리 플랫폼으로, 사용자가 쉽게 대화형 애플리케이션을 개발할 수 있도록 지원합니다. 이 플랫폼은 강력한 언어 모델과 사용자 친화적인 인터페이스를 제공하여 맞춤형 챗봇과 인공지능 솔루션을 구축할 수 있게 도와줍니다. 또한, 다양한 산업 분야에 적용 가능하며, 개발자와 비전문가 모두가 높은 수준의 AI 기능을 활용할 수 있도록 설계되어 있습니다.',\n",
       " 'Langgraph는 자연어 처리와 의미 분석을 위해 설계된 그래프 기반의 모델로, 언어 데이터를 노드와 엣지로 표현하여 의미 구조를 시각화합니다. 이 시스템은 텍스트 내의 단어와 문장 간의 관계를 효율적으로 파악하여 의미 연결성을 강화하는 데 사용됩니다. 결과적으로, Langgraph는 자연어 이해와 기계 번역, 질의응답 시스템 등 다양한 응용 분야에서 활용되어 높은 성능을 보여줍니다.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template('{topic}에 대해서 3문장으로 설명해줘')\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.batch([\n",
    "    {'topic': 'Langchain'},\n",
    "    {'topic': 'Langsmith'},\n",
    "    {'topic': 'Langgraph'},\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
